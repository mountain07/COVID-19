{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a44e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated By Kevin Du for OSGC Scholarship Program. Credits to \"Neural network powered COVID-19 spread forecasting model\"by Michał Wieczorek, Jakub Siłka, Marcin Woźniak for architecture and data processing.\\n\\nhttps://doi.org/10.1016/j.chaos.2020.110203\\n\\n~~notes notes notes\\nTODO: finish reading this paper https://osf.io/preprints/socarxiv/rn9xk\\nSecond Draft: implementation of policy data\\nPurpose:\\nIntended result:\\nNotes: \\n    Normalizing by the maximum infection rate hides a lot of the explainability of the model. The maximum infection rate\\n    of a state heavily depends on the population density, conformity to mask mandates, infection policies, etc. which are now\\n    potentially hidden due to the normalization\\n    \\n    Accuracy is heavily dependent on how many total points taken - having data from different strains to predict the next\\n    infection rate increases the loss dramatically\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created By Kevin Du for OSGC Scholarship Program. Credits to \"Neural network powered COVID-19 spread forecasting model\"\\\n",
    "by Michał Wieczorek, Jakub Siłka, Marcin Woźniak for architecture and data processing.\n",
    "\n",
    "https://doi.org/10.1016/j.chaos.2020.110203\n",
    "\n",
    "~~notes notes notes\n",
    "TODO: finish reading this paper https://osf.io/preprints/socarxiv/rn9xk\n",
    "Second Draft: implementation of policy data\n",
    "Purpose:\n",
    "Intended result:\n",
    "Notes: \n",
    "    Normalizing by the maximum infection rate hides a lot of the explainability of the model. The maximum infection rate\n",
    "    of a state heavily depends on the population density, conformity to mask mandates, infection policies, etc. which are now\n",
    "    potentially hidden due to the normalization\n",
    "    \n",
    "    Accuracy is heavily dependent on how many total points taken - having data from different strains to predict the next\n",
    "    infection rate increases the loss dramatically\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc597c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a24f2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##---------Data Hyperparameters-------------\n",
    "#number of days in a grouping\n",
    "time_step = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f4750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##---------Parameters of infection rate data----------\n",
    "#start date of infection data is 4/12/2020\n",
    "#end date of infection data is 1/7/2022\n",
    "##---------Import of infection rate data----------------\n",
    "\n",
    "#State/territory list (sorted alphabetically)\n",
    "statelist= [[] for _ in range(58)]\n",
    "\n",
    "#Total number of regions we are tracking\n",
    "state_list_size = len(statelist)\n",
    "\n",
    "#List of non-State and non-DC rows (start counting at 1)\n",
    "staterowlist=[4,11,15,16,41,46,54]\n",
    "\n",
    "#folderpath to \n",
    "folderpath = r\"C:\\Kevin\\Applications\\OSGC Undergraduate scholarship\\COVID-19\\COVID-19\\csse_covid_19_data\\csse_covid_19_daily_reports_us\" + \"\\\\\"\n",
    "\n",
    "with open(r\"C:\\Kevin\\Applications\\OSGC Undergraduate scholarship\\Date List.csv\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    datelist = list(reader)\n",
    "datelist=datelist[0]\n",
    "\n",
    "#total count of days of data\n",
    "count=len(datelist)\n",
    "\n",
    "for i in range(0, count):\n",
    "    splitdate = datelist[i].split(\"/\")\n",
    "    datelist[i] = splitdate[0] + \"-\" + splitdate[1] + \"-20\" + splitdate[2]\n",
    "\n",
    "#could optimize by adding the 'columns' as a row, then flipping everything with numpy\n",
    "\n",
    "#extract all the confirmed cases by date from all the data\n",
    "for date in datelist:\n",
    "    filepath = folderpath + date + \".csv\"\n",
    "    with open(filepath) as file:\n",
    "        reader = csv.reader(file)\n",
    "        data = list(reader)\n",
    "    for i in range(58):\n",
    "        statelist[i].append(data[i+1][5])\n",
    "    \n",
    "#Infection rates (Total cases) now stored in an array, with each row [first index] representing a state or region,\n",
    "#and each column [second index] representing a date for the infection\n",
    "    \n",
    "    \n",
    "#--------------Normalization of data------------   \n",
    "\n",
    "#Make numpy recognize that data is numerical\n",
    "statelist = np.array(statelist).astype(float)\n",
    "\n",
    "#Normalize by the highest infection rate\n",
    "#should maybe normalize by total population\n",
    "maxstatelist = np.amax(statelist, axis=1)\n",
    "statelist = statelist / maxstatelist[:,None]\n",
    "\n",
    "#Infection rates now in terms of (cases/max) with max as the highest one day infection cases\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "414b92d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485\n",
      "[33.54680928694236, 40.82493644703685, 78.85479355645913, 34.24736219450136, 29.238973029931707, 41.88354496685129]\n"
     ]
    }
   ],
   "source": [
    "##--------------------Import of policy data-------------------\n",
    "# retrieved from https://github.com/CoronaNetDataScience/corona_index\n",
    "\n",
    "df = pd.read_csv (r'C:\\Kevin\\Applications\\OSGC Undergraduate scholarship\\corona_index\\indices\\all_indices.csv')\n",
    "start_row = 502945\n",
    "end_row = 505854\n",
    "num_types = 6\n",
    "#start date is 1/1/2020\n",
    "#end date is 4/29/2021\n",
    "stacked_policy = []\n",
    "for i in range(int((end_row-start_row+1)/6)):\n",
    "    date_start_row = start_row + num_types*i\n",
    "    info = df['med_est'].iloc[date_start_row:date_start_row+num_types].to_list()\n",
    "    stacked_policy.append(info)\n",
    "print(len(stacked_policy))\n",
    "print(stacked_policy[102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aab7457c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of gstatelist is 21402, 20\n",
      "length of xtrain is 19140\n",
      "length of ytrain is 19140\n",
      "length of xval is 2262\n",
      "length of yval is 2262\n"
     ]
    }
   ],
   "source": [
    "##---------Training Hyperparameters-----------------------------\n",
    "test_size = 39\n",
    "\n",
    "\n",
    "##---------Imposed Parameters of Infection rate data----------\n",
    "#start date of infection data is 4/12/2020\n",
    "#end date of infection data is 1/7/2022 but policy data only goes to 4/29/2021\n",
    "start_date = 0\n",
    "end_date = 383\n",
    "#end date of total data set [policy data only goes to a certain point]\n",
    "#last number of days to use as test data\n",
    "test_date_size = 30\n",
    "#---------------Formatting of data---------------\n",
    "\n",
    "#Start date of collated data set is 4/12/2020\n",
    "#End date of collated data set is 4/29/2021\n",
    "#Since we are inputting 14 days of infection information initially, ytrain will start on 4/26/2020\n",
    "\n",
    "#grouping of data\n",
    "gstatelist=[]\n",
    "\n",
    "# group data into a list of first by start date, then by state. \n",
    "# Ex. The first 58 column arrays are the infection data for the first day of the 58 regions, in order\n",
    "for i in range(time_step, end_date): # represents the date before prediction\n",
    "    for j in range(state_list_size):\n",
    "        gstatelist.append(statelist[j,(i-time_step):i].tolist()+stacked_policy[102+i])\n",
    "\n",
    "xtrain_set=gstatelist[start_date*state_list_size:-test_size*state_list_size]\n",
    "xvalidation_set=gstatelist[-test_size*state_list_size:]\n",
    "\n",
    "ytrain_set=statelist[:,start_date+14:end_date-test_size].flatten().tolist()\n",
    "yvalidation_set=statelist[:,-test_size:].flatten().tolist()\n",
    "\n",
    "#Test print lines to be removed when finished with first draft\n",
    "print('shape of gstatelist is '+ str(len(gstatelist)) +', '+str(len(gstatelist[0])))\n",
    "print('length of xtrain is '+ str(len(xtrain_set)))\n",
    "print('length of ytrain is '+str(len(ytrain_set)))\n",
    "print('length of xval is '+ str(len(xvalidation_set)))\n",
    "print('length of yval is '+ str(len(yvalidation_set)))\n",
    "\n",
    "#Infection rates (input set) are now in sets of 14 days, with the last three months of data reserved for validation \n",
    "#(testing set will come from most recent data not included)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f984da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "#input_shape=(14,)\n",
    "#neuron\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(layers.Dense(units = 256, activation = 'tanh', input_shape = (20,)))\n",
    "#model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(units = 96, activation = 'tanh'))\n",
    "#model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(units = 48, activation = 'tanh'))\n",
    "model.add(layers.Dense(units = 28, activation = 'tanh'))\n",
    "model.add(layers.Dense(units = 48, activation = 'tanh'))\n",
    "model.add(layers.Dense(units = 12, activation = 'tanh'))\n",
    "model.add(layers.Dense(units = 6, activation = 'tanh'))\n",
    "model.add(layers.Dense(units = 1, activation = 'relu'))\n",
    "#need to find a better loss and metric for compiler for covid data- paper doesn't specify much past what is here\n",
    "model.compile(optimizer = 'Nadam', loss = 'mean_squared_error')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0f1fb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "599/599 [==============================] - 1s 731us/step - loss: 0.0690\n",
      "Epoch 2/3\n",
      "599/599 [==============================] - 0s 697us/step - loss: 0.0686\n",
      "Epoch 3/3\n",
      "599/599 [==============================] - 0s 666us/step - loss: 0.0686\n",
      "71/71 [==============================] - 0s 472us/step - loss: 0.7395\n",
      "0.7394986152648926\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(xtrain_set, ytrain_set, epochs =3)\n",
    "test_loss = model.evaluate(xvalidation_set, yvalidation_set)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab32d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
